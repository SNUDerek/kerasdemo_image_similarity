{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image similarity with youtube thumbnails\n",
    "\n",
    "## theory\n",
    "\n",
    "the `imagenet` competition was a task to classify a large series of images into a number of fine-grained categories. the intermediate layers of the competing networks were found to be informative vectors for a wide variety of image recognition tasks, roughly analogous to how word vectors formed from intermediate network layers capture latent features that represent word meaning. these \"feature vectors\" are sort of like coordinates that locate the images in an \"image space\", where similar images are closer together.\n",
    "\n",
    "we can leverage this to find similar images by embedding a set of images and using cosine similarity to compare a source to a target image. in layman's terms, cosine similarity tells us if the vectors are 'pointing in the same direction' which indicates that they are in similar points in the possible image embedding space (...roughly).\n",
    "\n",
    "we will use the YouTube API to get some video thumbnails of related videos for testing.\n",
    "\n",
    "### notes\n",
    "\n",
    "the 'most similar image' function is not reversible; image A may find image B as closest, but image B may say image C is closest. this is because C may be closer to B than A, but in an 'opposite' direction:\n",
    "\n",
    "`image_D <---|---|---|---|---> image_A <---|---|---> image_B <---|---> image_C <---|---|---> image_F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import scipy\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import youtube\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image vectorizer class\n",
    "`ImageVectorizer` class for obtaining image vectors from pretrained imagenet networks.  \n",
    "the vectors are the intermediate layer output of the network, before the dense classification layers, representing the latent image features.  \n",
    "by default, this uses the VGG16 network; pass the `model` and `preprocess_input` from the desired model to try other models.\n",
    "\n",
    "see https://keras.io/applications for details\n",
    "\n",
    "### references  \n",
    "https://github.com/dcdulin/image-classifier/blob/master/imagenetClassifier.py (primary source)  \n",
    "https://stackoverflow.com/questions/37751877/downloading-image-with-pil-and-requests (for better image loading)  \n",
    "https://keras.io/applications/#vgg16  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageVectorizer:\n",
    "    \"\"\"vectorizes image using pretrained Keras model\"\"\"\n",
    "    \n",
    "    def __init__(self, model=None, preprocess=None):\n",
    "        \"\"\"by default, use VGG16 model\"\"\"\n",
    "        if model is not None:\n",
    "            self.model=model\n",
    "        else:\n",
    "            self.model = keras.applications.vgg16.VGG16(include_top=False, \n",
    "                                                        weights='imagenet', \n",
    "                                                        input_tensor=None, \n",
    "                                                        input_shape=None, \n",
    "                                                        pooling='max')\n",
    "            \n",
    "        if preprocess is not None:\n",
    "            self.preprocess=preprocess_fn\n",
    "        else:\n",
    "            self.preprocess=keras.applications.vgg16.preprocess_input\n",
    "            \n",
    "        self.img_links = []\n",
    "        self.img_vectors = []\n",
    "        self.img_titles = []\n",
    "            \n",
    "            \n",
    "    def download_image(self, image_url):\n",
    "        \"\"\"\n",
    "        downloads and processes image from url\n",
    "        returns image vector, or None if didn't get response\n",
    "        \"\"\"\n",
    "        img_arr = None\n",
    "        buffer = tempfile.SpooledTemporaryFile(max_size=1e9)\n",
    "        r = requests.get(image_url, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            downloaded = 0\n",
    "            filesize = int(r.headers['content-length'])\n",
    "            for chunk in r.iter_content():\n",
    "                downloaded += len(chunk)\n",
    "                buffer.write(chunk)\n",
    "            # load image to buffer\n",
    "            # original source's approach led to disk thrashing and problems reading files\n",
    "            buffer.seek(0)\n",
    "            img = image.load_img(io.BytesIO(buffer.read()), target_size=(224,224))\n",
    "            buffer.close()\n",
    "            img_arr = image.img_to_array(img)\n",
    "        return img_arr\n",
    "\n",
    "    def vectorize(self, image_url):\n",
    "        \"\"\"vectorize single image with model\"\"\"\n",
    "        img_arr = self.download_image(image_url)\n",
    "        if img_arr is not None:\n",
    "            img_arr = np.expand_dims(img_arr, axis=0)\n",
    "            processed_img = self.preprocess(img_arr)\n",
    "            preds = self.model.predict(processed_img)\n",
    "            return preds[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def vectorize_links(self, image_url_list, image_title_list=None, debug=True):\n",
    "        \"\"\"vectorize set of images with model\"\"\"\n",
    "        # reset first\n",
    "        self.img_links = []\n",
    "        self.img_vectors = []\n",
    "        self.img_titles = []\n",
    "        \n",
    "        if image_title_list is not None:\n",
    "            self.img_titles = image_title_list\n",
    "            \n",
    "        vects = []\n",
    "        goods = []\n",
    "        for url in image_url_list:\n",
    "            time.sleep(0.1) # so not continually hitting links\n",
    "            v = self.vectorize(url)\n",
    "            if v is not None:\n",
    "                vects.append(v)\n",
    "                goods.append(url)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print('error:', url)\n",
    "                    \n",
    "        self.img_links = goods\n",
    "        self.img_vectors = vects\n",
    "        \n",
    "        return goods, vects\n",
    "    \n",
    "    # cosine similarity\n",
    "    def _cosine_similarity(self, vector1, vector2):\n",
    "        \"\"\"cosine similarity\"\"\"\n",
    "        return 1.-scipy.spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    def view_image(self, idx):\n",
    "        \"\"\"display image from index\"\"\"\n",
    "        if idx > len(self.img_vectors)-1:\n",
    "            print(\"index out of bounds!\")\n",
    "            return\n",
    "        i = Image(url=self.img_links[idx])\n",
    "        display(i)\n",
    "        return\n",
    "    \n",
    "    def image_similarity(self, idx):\n",
    "        \"\"\"compare images by cosine similarity and display the best match\"\"\"\n",
    "        if len(self.img_vectors) < 0:\n",
    "            print(\"please run vectorize_links() first!\")\n",
    "            return\n",
    "        if idx > len(self.img_vectors)-1:\n",
    "            print(\"index out of bounds!\")\n",
    "            return\n",
    "        test_img = self.img_links[idx]\n",
    "        test_vct = self.img_vectors[idx]\n",
    "        sims_vct = []\n",
    "        for i, vct in enumerate(self.img_vectors):\n",
    "            if i != idx:\n",
    "                sims_vct.append(self._cosine_similarity(test_vct, vct))\n",
    "            else:\n",
    "                sims_vct.append(0.0)\n",
    "        best_idx  = np.argmax(sims_vct)\n",
    "        o = Image(url=self.img_links[idx])\n",
    "        t = Image(url=self.img_links[best_idx])\n",
    "        display(o, t)\n",
    "        if len(self.img_titles) > best_idx:\n",
    "            return self.img_titles[best_idx]\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supporting functions\n",
    "\n",
    "`youtube.API` will be used for scraping images for this example.  \n",
    "You need a (free) API key for this: https://developers.google.com/youtube/registering_an_application\n",
    "\n",
    "see: https://github.com/rohitkhatri/youtube-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i've hidden my key for this demo\n",
    "api_key = pickle.load(open('googleAPIkey.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = youtube.API(client_id='', client_secret='', api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video ID\n",
    "# this is the last part of the youtube URL\n",
    "# we'll use [MV] IU(ÏïÑÏù¥Ïú†) _ BBIBBI(ÏÇêÏÇê)\n",
    "# https://www.youtube.com/watch?v=nM0xDI5R50E\n",
    "video_id = 'nM0xDI5R50E'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some related video URLs\n",
    "r = api.get('search', type='video', q=video_id, maxResults=50, part='snippet', regionCode='us', relevanceLanguage='en', key=api_key)\n",
    "urls = [i['snippet']['thumbnails']['medium']['url'] for i in r['items']]\n",
    "ttls = [i['snippet']['title'] for i in r['items']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MV] IU(ÏïÑÏù¥Ïú†) _ BBIBBI(ÏÇêÏÇê)\n",
      "https://i.ytimg.com/vi/nM0xDI5R50E/mqdefault.jpg\n",
      "IU(ÏïÑÏù¥Ïú†) _ BBIBBI(ÏÇêÏÇê) MV | BTS JUNGKOOK CRUSH? | REACTION!!!\n",
      "https://i.ytimg.com/vi/GyNFeZ6cgU0/mqdefault.jpg\n",
      "KPOP IDOLS Dancing &Singing To BbiBbi - IU üëØ\n",
      "https://i.ytimg.com/vi/eKo60MfiKwc/mqdefault.jpg\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for i in range(3):\n",
    "    print(ttls[i])\n",
    "    print(urls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vectorizer\n",
    "# this will download the image weights if you have not done so already\n",
    "vgg = ImageVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and vectorize each image\n",
    "img_links, img_vects = vgg.vectorize_links(urls, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data shape\n",
    "img_vects[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/1shgOutZH8s/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view a single image\n",
    "vgg.view_image(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/nM0xDI5R50E/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/hXvBoT3wtX8/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare by passing index of image to check\n",
    "# seems like the 0th item is always the original search query...?\n",
    "vgg.image_similarity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/wvsfBkTs86Q/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/HeYpZbRY0bw/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same template\n",
    "vgg.image_similarity(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/rIpBZnVOBZg/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/NakQsKtMzUU/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reaction videos\n",
    "vgg.image_similarity(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/wz0NsRsHlaE/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/8ME8woURUm0/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pastel title screens\n",
    "vgg.image_similarity(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/POYCKENtScQ/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/kz8ShKHecJs/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# both feature a character with their arms crossed\n",
    "vgg.image_similarity(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/Yo2Xv9LYTGI/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/gb9xJC-TCNE/mqdefault.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# computer screens\n",
    "vgg.image_similarity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
